{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer_rules = \"\"\"\n",
    "host = 主演 电影 评论\n",
    "主演 = 吴京 adj | 王宝强 adj | 周润发 adj\n",
    "adj = 的 | 这部 | 这个 | 这辆\n",
    "电影 = 杀破狼 | 战狼 | 唐人街探案 | 赌神 |\n",
    "评论 = 太好了 | 垃圾 | 恶心 | 好吃 | 车 adj | 稳住 | 不错\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammer(gram, line_split='\\n', word_split='='):\n",
    "    grammer = {}\n",
    "    for line in gram.split(line_split):\n",
    "        if not line: continue\n",
    "        key, value = line.split(word_split)\n",
    "        grammer[''.join(key.split())] = [val.split() for val in value.split('|')]\n",
    "    return grammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(sentence, target):\n",
    "    grammer = create_grammer(sentence)\n",
    "    if target not in grammer: \n",
    "        return target\n",
    "    sen = [generate(sentence, t) for t in random.choice(grammer[target])]\n",
    "    return ''.join(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(sentence, target, n):\n",
    "    for i in range(n):\n",
    "        yield generate(sentence, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_txt(string):\n",
    "    return re.findall('\\w+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_gram(path='word_gram.txt'):\n",
    "    with open(path, 'r') as f:\n",
    "        word_gram = [line.strip('\\n') for line in f.readlines() if line]\n",
    "    return Counter(word_gram)\n",
    "word_gram = word_gram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_2_gram(path='word_2_gram.txt'):\n",
    "    with open(path, 'r') as f:\n",
    "        word_2_gram = [line.strip('\\n') for line in f.readlines() if line]\n",
    "    return Counter(word_2_gram)\n",
    "word_2_gram = word_2_gram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-gram p(w1|w2)P(w2|w3)\n",
    "def get_sentence_prod(sentence):\n",
    "    sent = my_cut(sentence)\n",
    "    prod = 1\n",
    "    for i, value in enumerate(sent[:-2]):\n",
    "        p = (word_2_gram[sent[i] + sent[i+1]]) / (word_gram[sent[i+1]] + 1)\n",
    "        prod *= p if p else 1/len(word_gram) # 如果 p概率为0 用 1/len(word_gram)代替 是否合适？ \n",
    "    return (sentence, prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(n=5, comments=None, grammer=None, host=None):\n",
    "    \"\"\"\n",
    "    n: 生成句子数\n",
    "    comments: 评论列表\n",
    "    grammer：自定义语法\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    if comments:\n",
    "        for comm in comments:\n",
    "            result = [get_sentence_prod(comm) for comm in comments if comm]\n",
    "    else:\n",
    "        for i in generate_n(grammer, host, n):\n",
    "            result.append(get_sentence_prod(i))\n",
    "    return sorted(result, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_comment = generate_best(grammer=grammer_rules, host='host')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('吴京的不错', 0.0001523168922479841),\n",
       " ('王宝强的车这部', 1.5083808746887745e-05),\n",
       " ('王宝强这部太好了', 6.083021071584992e-06),\n",
       " ('吴京这个唐人街探案稳住', 6.803259474632783e-10),\n",
       " ('吴京这辆杀破狼稳住', 1.5495454504751688e-12)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_comment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
